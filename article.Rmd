---
title: "Playing Atari with Keras and R"
author: "Daniel Falbel and Fernando Barscevicius"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
```

In this article we will implement the famous paper from DeepMind: [*Playing Atari with Deep Reinforcement Learning*](https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf) in R using Keras. This paper introduced the first deep learning model that successfully learned control policies directly from high-dimensional sensory input using reinforcement learning.

The DeepMinds's algorithm is trained on raw pixels from Atari games and estimates future rewards for each possible action. The model is a convolutional neural network trained with a variant of the [Q-Learning](https://en.wikipedia.org/wiki/Q-learning) algorithm, which we will attempt to explain during this article.

The code was not published with the paper, but the results were reproduced and published by severeal people on the internet. Particularly, [this post](https://yanpanlau.github.io/2016/07/10/FlappyBird-Keras.html) and the [referenced implementation](https://github.com/yenchenlin/DeepLearningFlappyBird) were very useful when writing this article. Also, [this article](https://becominghuman.ai/lets-build-an-atari-ai-part-1-dqn-df57e8ff3b26) from [Becoming Human](https://becominghuman.ai) was very inspiring.

We only tested our implementation for the Atari Breakout game, but it should also work for other Atari games.

# Reinforcement Learning

Reinforcement learning is an area of Machine Learning that has been gaining a lot of attention recently. A good definition comes from Sutton and Barto's book *Reinforcement Learning: An Introduction*:

> Reinforcement learning is learning what to do—how to map situations to actions—so as to maximize a numerical reward signal. The learner is not told which actions to take, but instead must discover which actions yield the most reward by trying them. In the most interesting and challenging cases, actions may affect not only the immediate reward but also the next situation and, through that, all subsequent rewards. These two characteristics—trial-and-error search and delayed reward—are the two most important distinguishing features of reinforcement learning.

Reinforcement learning is being used to solve many problems in robotics, delivery management or in the finance sector.

## Q-Learning

Q-learning, [as defined by it's creator](https://link.springer.com/content/pdf/10.1007%2FBF00992698.pdf), *is a form of model-free reinforcement learning. It can also be viewed as a method of asynchronous dynamic programming (DP). It provides agents with the capability of learning to act optimally in Markovian domains by experiencing the consequences of actions, without requiring them to build maps of the domains.*

Put in simple terms, Q-learning is an algorithm that allows for the selection of the best possible action to perform given the current state of the environment. It works by assigning each state an estimated value **(Q-value)**. Then, by interacting with the state and receiveing a reward, the estimated value is updated. We can write this Q-value as $\mathbf{Q(s, a)}$ and the updates are given by $\mathbf{Q(s, a) = Q(s, a) + \alpha(R(s) + γmax_{a'}Q(s_0, a_0) − Q(s, a))}$ (more information about the mathematics and the workings of the Q-learning algorithm can be found [here](http://neuro.cs.ut.ee/demystifying-deep-reinforcement-learning/)).

As we have to keep track of the Q-values for every state, storing and updating them in a Q-table, Q-learning can become very ineffective for bigger environments. That's where Deep Q-Learning comes into play, substituting the enormous Q-table for a lighter Neural Network.

## Deep Q-Learning

### Frame stacking

### Experience Replay

# Implementation in R

Now we will start implementing the Deep Q-Learning algorithm in R. But first, we need a game emulator. That's where [OpenAI gym](https://gym.openai.com) comes handy. 

## Gym

> Gym is a toolkit for developing and comparing reinforcement learning algorithms. It supports teaching agents everything from walking to playing games like Pong or Pinball.

The `gym` framework is available to python and we will use reticulate to run it from R. To install it, you can run:

```{r}
library(reticulate)
py_install("gym[atari]", envname = "r-tensorflow")
```

You must be careful to install it to the same environment that Keras and TensorFlow are installed since we will need to load all of them in the same session. Gym has lot's of dependencies that are not installed by default, to install the Atari dependencies that we are going to use we used `gym[atari]` in the pip package name.

Now that we have Gym installed we can "make" an environment and run some random actions to understand how it works.











